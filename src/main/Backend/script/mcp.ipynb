{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# Add path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Автоперезагрузка файлов\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set env\n",
    "os.environ[\"PYTHONDONTWRITEBYTECODE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "from contextlib import AsyncExitStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_stack = AsyncExitStack()\n",
    "\n",
    "url = \"http://app_baylang_ai/api/chat/sse\"\n",
    "read, write = await exit_stack.enter_async_context(sse_client(url=url))\n",
    "session = await exit_stack.enter_async_context(ClientSession(read, write))\n",
    "\n",
    "# Init\n",
    "await session.initialize()\n",
    "\n",
    "# List available tools\n",
    "response = await session.list_tools()\n",
    "tools = response.tools\n",
    "print(\"\\nConnected to server with tools:\", [tool.name for tool in tools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call magic function\n",
    "result = await session.call_tool(\"magic_function\", {\"a\": 12})\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app import App\n",
    "\n",
    "# Create app\n",
    "main_app = App()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOllama(\n",
    "            base_url=\"http://database_ollama:11434\",\n",
    "            model=\"qwen2.5:3b\",\n",
    "            temperature=0.5,\n",
    "        )\n",
    "    \n",
    "    def forward(self, message):\n",
    "        return \"\"\n",
    "\n",
    "question = Question(\n",
    "    content=\"Выполни волшебную функцию над числом 5, а затем результат передай еще раз в волшебную функцию. Ответ:\"\n",
    ")\n",
    "\n",
    "agent = Agent()\n",
    "answer = agent.forward(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
